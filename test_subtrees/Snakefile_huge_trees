import os

# To run locally:
# snakemake --snakefile Snakefile_huge_trees --keep-going --cores 4


# To visualise the pipeline:
# snakemake --snakefile Snakefile_huge_trees --dag | dot -Tsvg > pipeline_huge_trees.svg

localrules: all

sim_folder = os.path.abspath(os.path.join('..', 'data_publication'))
models = ['BD', 'BDSS', 'BDEI']
models = ['BD']
REPETITIONS=100

rule all:
    input:
        nwk = expand(os.path.join(sim_folder, 'Supp_Fig_10', 'test_trees', '{model}_huge_100.nwk.gz'), model=models),
        errors = expand(os.path.join(sim_folder, 'Supp_Fig_10', 'predicted_values', '{model}_errors.png'), model=models),
        logs = expand(os.path.join(sim_folder, 'Supp_Fig_10', 'predicted_values', '{model}_huge', '{name}_log.csv.gz'), model=models, name=['CNN_CBLV', 'FFNN_SS'])


#rule split:
#    '''
#    Splits a forest into trees.
#    '''
#    input:
#        nwk = os.path.join(sim_folder, 'Supp_Fig_10', 'test_trees', '{model}_huge_100.nwk.gz'),
#        log = os.path.join(sim_folder, 'Supp_Fig_10', 'predicted_values', '{model}_huge', 'TARGET.csv.gz'),
#    output:
#        nwk = temp(expand(os.path.join(sim_folder, 'Supp_Fig_10', 'test_trees', '{{model}}_huge_100.{i}.nwk'), i=range(REPETITIONS))),
#        log = temp(expand(os.path.join(sim_folder, 'Supp_Fig_10', 'predicted_values', '{{model}}_huge', 'TARGET.{i}.csv'), i=range(REPETITIONS)))
#    params:
#        mem = 2000,
#        name = 'split',
#        qos = 'fast'
#    threads: 1
#    shell:
#        """
#        python3 main_split.py --in_log {input.log} --in_nwk {input.nwk} --out_nwk {output.nwk} --out_log {output.log}
#        """


rule simulate_bd:
    '''
    Simulates a tree for given BD parameters.
    '''
    input:
        log = os.path.join(sim_folder, 'Fig_3', 'predicted_values', 'BD_large', 'TARGET.csv.gz'),
    output:
        nwk = temp(os.path.join(sim_folder, 'Supp_Fig_10', 'test_trees', 'BD_huge_100.{i}.nwk')),
        log = temp(os.path.join(sim_folder, 'Supp_Fig_10', 'predicted_values', 'BD_huge', 'TARGET.{i}.csv')),
    params:
        mem = 2000,
        name = 'tree_large_{i}',
        qos = 'fast'
    threads: 1
    shell:
        """
        line=`gzip -dc {input.log} | head -n $(({wildcards.i} + 2)) | tail -n 1 `

        R=`echo $line | cut -d, -f1`
        ip=`echo $line | cut -d, -f2`
        p=`echo $line | cut -d, -f4`
        psi=`bc -l <<< "1/$ip"`
        la=`bc -l <<< "$R/$ip"`

        generate_bd --min_tips 5000 --max_tips 10000 --la $la --psi $psi --p $p \
        --nwk {output.nwk} --log {output.log}
        """

rule simulate_bdei:
    '''
    Simulates a tree for given BDEI parameters.
    '''
    input:
        log = os.path.join(sim_folder, 'Fig_3', 'predicted_values', 'BDEI_large', 'TARGET.csv.gz'),
    output:
        nwk = temp(os.path.join(sim_folder, 'Supp_Fig_10', 'test_trees', 'BDEI_huge_100.{i}.nwk')),
        log = temp(os.path.join(sim_folder, 'Supp_Fig_10', 'predicted_values', 'BDEI_huge', 'TARGET.{i}.csv')),
    params:
        mem = 2000,
        name = 'tree_large_{i}',
        qos = 'fast'
    threads: 1
    shell:
        """
        line=`gzip -dc {input.log} | head -n $(({wildcards.i} + 2)) | tail -n 1 `

        R=`echo $line | cut -d, -f1`
        ip=`echo $line | cut -d, -f2`
        it=`echo $line | cut -d, -f3`
        p=`echo $line | cut -d, -f5`
        mu=`bc -l <<< "1/$ip"`
        psi=`bc -l <<< "1/$it"`
        la=`bc -l <<< "$R/$it"`

        generate_bdei --min_tips 5000 --max_tips 10000 --mu $mu --la $la --psi $psi --p $p \
        --nwk {output.nwk} --log {output.log}
        """

rule simulate_bdss:
    '''
    Simulates a tree for given BD parameters.
    '''
    input:
        log = os.path.join(sim_folder, 'Fig_3', 'predicted_values', 'BDSS_large', 'TARGET.csv.gz'),
    output:
        nwk = temp(os.path.join(sim_folder, 'Supp_Fig_10', 'test_trees', 'BDSS_huge_100.{i}.nwk')),
        log = temp(os.path.join(sim_folder, 'Supp_Fig_10', 'predicted_values', 'BDSS_huge', 'TARGET.{i}.csv')),
    params:
        mem = 2000,
        name = 'tree_large_{i}',
        qos = 'fast'
    threads: 1
    shell:
        """
        line=`gzip -dc {input.log} | head -n $(({wildcards.i} + 2)) | tail -n 1 `

        R=`echo $line | cut -d, -f1`
        x=`echo $line | cut -d, -f2`
        f=`echo $line | cut -d, -f3`
        ip=`echo $line | cut -d, -f4`
        p=`echo $line | cut -d, -f6`
        psi=`bc -l <<< "1/$ip"`
        fx=`bc -l <<< $f*$x`
        la=`bc -l <<< "$R/$ip"`
        bss=`bc -l <<< "$la*$fx/($fx+1-$f)"`
        bns=`bc -l <<< "$bss/$x"`
        bnn=`bc -l <<< "$la-$bss"`
        bsn=`bc -l <<< "$bnn*$x"`

        generate_bdss --min_tips 5000 --max_tips 10000 --la_ss $bss --la_sn $bsn --la_ns $bns --la_nn $bnn \
        --psi $psi --p $p \
        --nwk {output.nwk} --log {output.log}
        """

rule combine_nwks:
    '''
    Combines nwk trees.
    '''
    input:
        nwk = expand(os.path.join(sim_folder, 'Supp_Fig_10', 'test_trees', '{{model}}_huge_100.{i}.nwk'), i=range(REPETITIONS)),
    output:
        nwk = os.path.join(sim_folder, 'Supp_Fig_10', 'test_trees', '{model}_huge_100.nwk.gz'),
    params:
        nwk = os.path.join(sim_folder, 'Supp_Fig_10', 'test_trees', '{model}_huge_100.nwk'),
        nwk_pattern = os.path.join(sim_folder, 'Supp_Fig_10', 'test_trees', '{model}_huge_100.$i.nwk'),
        mem = 2000,
        name = 'combine_{model}',
        qos = 'fast'
    threads: 1
    shell:
        """
        rm -rf {output.nwk} {params.nwk}
        for i in {{0..99}}
        do
            cat {params.nwk_pattern} >> {params.nwk}
        done
        gzip {params.nwk}
        """

rule combine_logs:
    '''
    Combines logs.
    '''
    input:
        log = expand(os.path.join(sim_folder, 'Supp_Fig_10', 'predicted_values', '{{model}}_huge', '{{name}}.{i}.csv'), i=range(REPETITIONS))
    output:
        log = os.path.join(sim_folder, 'Supp_Fig_10', 'predicted_values', '{model}_huge', '{name}.csv.gz'),
    params:
        log = os.path.join(sim_folder, 'Supp_Fig_10', 'predicted_values', '{model}_huge', '{name}.csv'),
        log_pattern = os.path.join(sim_folder, 'Supp_Fig_10', 'predicted_values', '{model}_huge', '{name}.$i.csv'),
        mem = 2000,
        name = 'combine_{model}',
        qos = 'fast'
    threads: 1
    shell:
        """
        rm -rf {output.log} {params.log}
        for i in {{0..99}}
        do
            if [ $i -eq 0 ]
            then
                cat {params.log_pattern} > {params.log}
            else
                tail -n 1 {params.log_pattern} >> {params.log}
            fi
        done
        gzip {params.log}
        """

rule estimate_cnn:
    '''
    Extracts the oldest part of the subtree, estimates parameters on it.
    '''
    input:
        nwk = os.path.join(sim_folder, 'Supp_Fig_10', 'test_trees', '{model}_huge_100.{i}.nwk'),
        log = os.path.join(sim_folder, 'Supp_Fig_10', 'predicted_values', '{model}_huge', 'TARGET.{i}.csv'),
    output:
        est_CNN = temp(os.path.join(sim_folder, 'Supp_Fig_10', 'predicted_values', '{model}_huge', 'CNN_CBLV.{i}.csv')),
        log_CNN = temp(os.path.join(sim_folder, 'Supp_Fig_10', 'predicted_values', '{model}_huge', 'CNN_CBLV_log.{i}.csv')),
    params:
        mem = 2000,
        name = 'subtrees_{model}.{i}',
        qos = 'fast'
    threads: 1
    shell:
        """
        pcol=`head -n 1 {input.log} | tr ',' '\\n' | cat -n | grep "sampling" | cut -f 1`
        p=`tail -n 1 {input.log} | cut -d, -f$pcol `
        paramdeep -t {input.nwk} -p $p -m {wildcards.model} -v CNN_FULL_TREE -o {output.est_CNN} > {output.log_CNN}
        """

rule estimate_ffnn:
    '''
    Extracts the oldest part of the subtree, estimates parameters on it.
    '''
    input:
        nwk = os.path.join(sim_folder, 'Supp_Fig_10', 'test_trees', '{model}_huge_100.{i}.nwk'),
        log = os.path.join(sim_folder, 'Supp_Fig_10', 'predicted_values', '{model}_huge', 'TARGET.{i}.csv'),
    output:
        est_FFNN = temp(os.path.join(sim_folder, 'Supp_Fig_10', 'predicted_values', '{model}_huge', 'FFNN_SS.{i}.csv')),
        log_FFNN = temp(os.path.join(sim_folder, 'Supp_Fig_10', 'predicted_values', '{model}_huge', 'FFNN_SS_log.{i}.csv')),
    params:
        mem = 2000,
        name = 'subtrees_{model}.{i}',
        qos = 'fast'
    threads: 1
    shell:
        """
        pcol=`head -n 1 {input.log} | tr ',' '\\n' | cat -n | grep "sampling" | cut -f 1`
        p=`tail -n 1 {input.log} | cut -d, -f$pcol `
        paramdeep -t {input.nwk} -p $p -m {wildcards.model} -v FFNN_SUMSTATS -o {output.est_FFNN} > {output.log_FFNN}
        """


rule combine_estimates:
    '''
    Combine estimates.
    '''
    input:
        est_CNN = os.path.join(sim_folder, 'Supp_Fig_10', 'predicted_values', '{model}_huge', 'CNN_CBLV.csv.gz'),
        est_FFNN = os.path.join(sim_folder, 'Supp_Fig_10', 'predicted_values', '{model}_huge', 'FFNN_SS.csv.gz'),
        real = os.path.join(sim_folder, 'Supp_Fig_10', 'predicted_values', '{model}_huge', 'TARGET.csv.gz'),
        real_b = os.path.join(sim_folder, 'Fig_3', 'predicted_values', '{model}_large', 'TARGET.csv.gz'),
        est_CNN_large = os.path.join(sim_folder, 'Fig_3', 'predicted_values', '{model}_large', 'CNN_CBLV.csv.gz'),
        est_FFNN_large = os.path.join(sim_folder, 'Fig_3', 'predicted_values', '{model}_large', 'CNN_CBLV.csv.gz'),
    output:
        tab = os.path.join(sim_folder, 'Supp_Fig_10', 'predicted_values', '{model}_estimates.tab'),
    params:
        mem = 2000,
        name = 'estimates',
        qos = 'fast',
    threads: 1
    shell:
        """
        python3 main_summary_table.py --real {input.real} --real_b {input.real_b} \
        --estimated_CNN {input.est_CNN} --estimated_FFNN {input.est_FFNN}  \
        --estimated_CNN_large {input.est_CNN_large} --estimated_FFNN_large {input.est_FFNN_large} \
        --tab {output.tab} --model {wildcards.model}
        """

rule plot_errors:
    '''
    Plots the errors.
    '''
    input:
        tab = os.path.join(sim_folder, 'Supp_Fig_10', 'predicted_values', '{model}_estimates.tab'),
    output:
        png = os.path.join(sim_folder, 'Supp_Fig_10', 'predicted_values', '{model}_errors.png'),
    params:
        mem = 2000,
        name = 'errors',
        qos = 'fast'
    threads: 1
    shell:
        """
        python3 main_plot_error.py --estimates {input.tab} --png {output.png}
        """